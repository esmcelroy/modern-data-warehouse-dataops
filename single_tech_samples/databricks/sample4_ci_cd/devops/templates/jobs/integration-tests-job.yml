parameters:
- name: environmentName
  type: string
- name: databricksDomain
  type: string
- name: databricksToken
  type: string
- name: databricksNotebookPath
  type: string
- name: databricksClusterId
  type: string

jobs:
- deployment: run_integration_tests
  environment: ${{ parameters.environmentName }}
  displayName: 'Run integration tests'
  dependsOn: deploy_notebooks
  pool:
    vmImage: 'ubuntu-latest'
  variables:
    pythonWorkingDir: 'single_tech_samples/databricks/sample4_ci_cd/notebook-dataframe'
    pythonVersion: 3.8
  strategy:
    runOnce:
      deploy:
        steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(pythonVersion)'
            addToPath: true
            architecture: 'x64'
          displayName: 'Use Python Version: $(pythonVersion)'

        - script: pip install pytest requests
          displayName: 'Install requirements'

        - script: mkdir -p $(Pipeline.Workspace)/logs/json $(Pipeline.Workspace)/logs/xml
          displayName: 'Create notebook execution logs and test summaries output'

        - task: PythonScript@0
          inputs:
            scriptPath: $(Pipeline.Workspace)/ci/devops_scripts/executenotebook.py
            arguments: --shard ${{ parameters.databricksDomain }} --token ${{ parameters.databricksToken }} --clusterid ${{ parameters.databricksClusterId }} --localpath $(Pipeline.Workspace)/ci/notebooks --workspacepath ${{ parameters.databricksNotebookPath }} --outfilepath $(Pipeline.Workspace)/logs/json
          displayName: 'Run integration tests'

        - script: TEST_OUTPUT_PATH=$(Pipeline.Workspace)/logs/json/ python -m pytest --junit-xml=$(Pipeline.Workspace)/logs/xml/TEST-notebookout.xml $(Pipeline.Workspace)/ci/devops_scripts/evaluatenotebookruns.py || true
          displayName: 'Evaluate test results'

        - task: PublishTestResults@2
          inputs:
            testResultsFiles: $(Pipeline.Workspace)/logs/xml/TEST-notebookout.xml